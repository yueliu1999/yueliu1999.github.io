<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Yue Liu</title>

  <meta name="author" content="Yue Liu">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
      <style>
    .projects-box {
      /* background-color: green; */
      height: 160px;
      position: relative;
      overflow: hidden;
      transition: all ease-in .1s;

    }
    .projects-show {
      padding: 0;
      margin: 0;
      position: absolute;
      bottom: 0;
      left: 0;
      text-align: center;
      height: 30px;
      line-height: 20px;
      width: 100%;
      font-size: 12px;
      color: #0067c8;
      cursor: pointer;
      background: linear-gradient(to bottom, transparent, #fff, #fff);
    }
    .projects-show-text {
      position: relative;
      top: 10px;
    }
    .category-btn {
      padding: 8px 16px;
      margin: 5px;
      border: 1px solid #0067c8;
      background-color: white;
      color: #0067c8;
      cursor: pointer;
      border-radius: 4px;
      font-size: 14px;
      transition: all 0.3s ease;
    }
    .category-btn:hover {
      background-color: #f0f7ff;
    }
    .category-btn.active {
      background-color: #0067c8;
      color: white;
    }
    .paper-row {
      transition: opacity 0.3s ease;
    }
    .paper-row.hidden {
      display: none;
    }
    .paper-tag {
      float: right;
      padding: 3px 8px;
      margin-left: 12px;
      background-color: #0067c8;
      color: white;
      border-radius: 3px;
      font-size: 11px;
      font-weight: normal;
      vertical-align: middle;
    }
    .author-link {
      color: inherit;
      text-decoration: none;
    }
    .author-link:hover {
      text-decoration: underline;
    }
  </style>
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Yue Liu</name>
              </p>


              <p style="text-align:justify">Yue Liu (ÂàòÊÇ¶) is a PhD student at <a href="https://nus.edu.sg/">National University of Singapore</a>, where he is fortunate to be advised by Prof. <a href="https://bhooi.github.io/">Bryan Hooi</a> and Prof. <a href="https://zjhzjh123.github.io/">Jiaheng Zhang</a>. 
<!--               <p style="text-align:justify"></a>.  -->
		      
		      
		      
              </p>

              <p style="text-align:center">
                <a href="yueliu19990731@163.com">Email</a> &nbsp/&nbsp
<!--                <a href="data/YueLiu-CV.pdf">CV</a> &nbsp/&nbsp-->
<!--                <a href="data/YueLiu-bio.txt">Bio</a> &nbsp/&nbsp-->
                <a href="https://scholar.google.com/citations?user=5tfpu3MAAAAJ&hl=zh-CN/">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/lyq_q/">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/yueliu1999/">Github</a> 
<!-- 		      &nbsp/&nbsp -->
<!--                 <a href="images/GF.png">GF</a> -->
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/liuyue_2.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/liuyue_2.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
              <ul class="projects-box" id="projects-box">
	      <li><b>[<font color="red">2026.02</font>]</b> One paper has been accepted by <em>IEEE T-KDE</em>.</li>
	      <li><b>[<font color="red">2026.02</font>]</b> Won Student Research Award from NUS.</li>
	      <li><b>[<font color="red">2025.12</font>]</b> Won Dean's Graduate Research Excellence Award from NUS.</li>
	      <li><b>[<font color="red">2025.11</font>]</b> Two papers have been accepted by <em>AAAI</em> 2025 (one Oral).</li>
	      <li><b>[<font color="red">2025.09</font>]</b> One paper has been accepted by <em>IEEE T-NNLS</em>.</li>
	      <li><b>[<font color="red">2025.09</font>]</b> Three papers have been accepted by <em>NeurIPS</em> 2025 (one Spotlight).</li>
	      <li><b>[<font color="red">2025.09</font>]</b> Won Intech Award (PhD Track) from Ant Group.</li>
	      <li><b>[<font color="red">2025.08</font>]</b> Two papers have been accepted by <em>EMNLP</em> 2025.</li>
	      <li><b>[<font color="red">2025.07</font>]</b> One paper has been accepted by <em>ACM MM</em> 2025.</li>
	      <li><b>[<font color="red">2025.06</font>]</b> One paper has been accepted by <em>ICCV</em> 2025 (one Highlight).</li>
	      <li><b>[<font color="red">2025.05</font>]</b> One paper has been accepted by <em>ACL</em> 2025.</li>
	      <li><b>[<font color="red">2025.05</font>]</b> One paper has been accepted by <em>KDD</em> 2025.</li>
	      <li><b>[<font color="red">2025.05</font>]</b> Four papers have been accepted by <em>ICML</em> 2025 (one Spotlight).</li>
	      <li><b>[<font color="red">2025.03</font>]</b> One paper has been accepted by <em>IEEE T-PAMI</em>.</li>
	      <li><b>[<font color="red">2025.03</font>]</b> One paper has been accepted by <em>IEEE T-MM</em>.</li>
<!-- 	      <li><b>[<font color="red">2025.03</font>]</b> Four paper has been accepted by <em>ICLR Workshop</em> 2025.</li> -->
	      <li><b>[<font color="red">2025.01</font>]</b> One paper has been accepted by <em>ICLR</em> 2025.</li>
	      <li><b>[<font color="red">2025.01</font>]</b> One paper has been accepted by <em>WWW</em> 2025 (Oral).</li>
	      <li><b>[<font color="red">2024.12</font>]</b> One paper has been accepted by <em>OFC</em> 2025 (Oral).</li>
	      <li><b>[<font color="red">2024.12</font>]</b> One paper has been accepted by <em>AAAI</em> 2025 (Oral).</li>
<!-- 	      <li><b>[<font color="red">2024.09</font>]</b> Two papers have been accepted by <em>NeurIPS (D&B Track)</em> 2024.</li> -->
<!-- 	      <li><b>[<font color="red">2024.09</font>]</b> Two papers have been accepted by <em>NeurIPS Workshop</em> 2024.</li> -->
	      <li><b>[<font color="red">2024.09</font>]</b> Four papers have been accepted by <em>NeurIPS</em> 2024.</li>
	      <li><b>[<font color="red">2024.09</font>]</b> One paper has been accepted by <em>IEEE T-KDE</em>.</li>
              <li><b>[<font color="red">2024.08</font>]</b> Won President's Graduate Fellowship from NUS.</li>
	      <li><b>[<font color="red">2024.07</font>]</b> Two papers have been accepted by <em>ACM MM</em> 2024.</li>
	      <li><b>[<font color="red">2024.07</font>]</b> One paper has been accepted by <em>IEEE T-NNLS</em>.</li>
	      <li><b>[<font color="red">2024.06</font>]</b> One paper has been accepted by <em>IEEE T-PAMI</em>.</li>
	      <li><b>[<font color="red">2024.05</font>]</b> One paper has been accepted by <em>IEEE T-NNLS</em>.</li>
	      <li><b>[<font color="red">2024.05</font>]</b> One paper has been accepted by <em>ICML</em> 2024 (Spotlight).</li>
	      <li><b>[<font color="red">2024.01</font>]</b> One paper has been accepted by <em>IEEE T-KDE</em>.</li>
	      <li><b>[<font color="red">2024.01</font>]</b> Two papers have been accepted by <em>ICLR</em> 2024 (one Spotlight).</li>
	      <li><b>[<font color="red">2024.01</font>]</b> One papers has been accepted by <em>IEEE T-NNLS</em>.</li>
	      <li><b>[<font color="red">2023.12</font>]</b> Three papers have been accepted by <em>AAAI</em> 2024 (Oral).</li>
	      <li><b>[<font color="red">2023.12</font>]</b> One paper has been accepted by <em>ICDE</em> 2024.</li>
              <li><b>[<font color="red">2023.11</font>]</b> Won China National Scholarship</li>
	      <li><b>[<font color="red">2023.09</font>]</b> One paper has been accepted by <em>NeurIPS</em> 2023.</li>
	      <li><b>[<font color="red">2023.07</font>]</b> Four papers have been accepted by <em>ACM MM</em> 2023.</li>
	      <li><b>[<font color="red">2023.07</font>]</b> One paper has been accepted by <em>IEEE T-NNLS</em>.</li>
	      <li><b>[<font color="red">2023.06</font>]</b> One paper has been accepted by <em>IEEE T-KDE</em>.</li>
              <li><b>[<font color="red">2023.04</font>]</b> One paper has been accepted by <em>ICML</em> 2023.</li>
              <li><b>[<font color="red">2023.04</font>]</b> One paper has been accepted by <em>IEEE T-NNLS</em>.</li>
              <li><b>[<font color="red">2023.04</font>]</b> One paper has been accepted by <em>SIGIR</em> 2023.</li>
              <li><b>[<font color="red">2023.01</font>]</b> One paper has been accepted by <em>ICLR</em> 2023.</li>
              <li><b>[<font color="red">2022.12</font>]</b> Won China National Scholarship</li>
              <li><b>[<font color="red">2022.11</font>]</b> Three papers have been accepted by <em>AAAI</em> 2023.</li>
              <li><b>[<font color="red">2022.06</font>]</b> One paper has been accepted by <em>ACM MM</em> 2022.</li>
              <li><b>[<font color="red">2022.04</font>]</b> One paper has been accepted by <em>IJCAI</em> 2022.</li>
              <li><b>[<font color="red">2021.12</font>]</b> One paper has been accepted by <em>AAAI</em> 2022.</li>
              <li><b>[<font color="red">2020.12</font>]</b> Won China National Scholarship</li>
                  <p class="projects-show" id="projects-show"><span class="projects-show-text" id="projects-show-text">More</span></p>

              </ul>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              
              <p>
                My research mainly focuses on self-supervised learning and its applications in the following areas:
              </p>
              <ul>
                <li>Foundation Models (e.g., intelligence & safety of LLMs, MLLMs, and agentic models)</li>
                <li>Graph Learning (e.g., graph clustering, knowledge graph embedding, and recommendation systems)</li>
              </ul>




              
              <div style="margin-bottom: 20px;">
                <button class="category-btn active" data-category="all" onclick="filterPapers('all')">All</button>
                <button class="category-btn" data-category="foundation-models" onclick="filterPapers('foundation-models')">Intelligence of Foundation Models</button>
                <button class="category-btn" data-category="llm-safety" onclick="filterPapers('llm-safety')">Safety of Foundation Models</button>
                
                <span style="white-space: nowrap; display: inline-block;">
                  <button class="category-btn" data-category="graph-clustering" onclick="filterPapers('graph-clustering')">Graph Clustering</button>
                  <button class="category-btn" data-category="recommendation" onclick="filterPapers('recommendation')">Recommendation Systems</button>
                  <button class="category-btn" data-category="knowledge-graph" onclick="filterPapers('knowledge-graph')">Knowledge Graph Embedding</button>
                </span>
              </div>
              * denotes equal contributions. The selected papers are listed as follows.
            
            </td>
          </tr>
        </tbody></table>


<!--        paper_list-->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


			

                    <!--------------------------------------------------------------------------------------------------------------------------->
                    <tr class="paper-row" data-category="foundation-models">
                      <!-- 		    bgcolor="#ffffd0" -->
                      <!--              -->
                                  <td style="padding:20px;width:25%;vertical-align:middle">
                                    <div class="one">
                                      <img src='images/klong.png' width="160">
                                    </div>
                                  </td>
                                  <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://arxiv.org/abs/2602.17547">
                                      <papertitle style="font-size: 0.92em;">KLong: Training LLM Agent for Extremely Long-horizon Tasks</papertitle>
                                    </a>
                                    <br>
                                    <strong>Yue Liu</strong>, Zhiyuan Hu, Flood Sung, Jiaheng Zhang, Bryan Hooi
                                    <br>
                                    <em>arXiv</em>, 2026
                                    <br>
                                    <a href="https://arxiv.org/abs/2602.17547">Paper</a>
                                    /
                                    <a href="https://github.com/yueliu1999/KLong">Code</a>
                                    <p></p>
                                      <p style="text-align:justify">


                                        We introduce a new LLM agent, KLong, to solve extremely long-horizon tasks such as replicating research. We develop a research-factory to scale the training data for replicating the research task. Then, KLong is trained via trajectory-splitting SFT and progressive RL.
                                      </p>
                                  </td>
                                </tr>
                      <!--------------------------------------------------------------------------------------------------------------------------->
              


			

                    <!--------------------------------------------------------------------------------------------------------------------------->
                    <tr class="paper-row" data-category="llm-safety">
                      <!-- 		    bgcolor="#ffffd0" -->
                      <!--              -->
                                  <td style="padding:20px;width:25%;vertical-align:middle">
                                    <div class="one">
                                      <img src='images/guardreaonser_omni.png' width="160">
                                    </div>
                                  </td>
                                  <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://arxiv.org/abs/2602.03328">
                                      <papertitle style="font-size: 0.92em;">GuardReasoner-Omni: A Reasoning-based Multi-modal Guardrail for Text, Image, and Video</papertitle>
                                    </a>
                                    <br>
                                    Zhenhao Zhu*, <strong>Yue Liu*</strong>, Yanpei Guo, Wenjie Qu, Cancan Chen, Yufei He, Yibo Li, Yulin Chen, Tianyi Wu, Huiying Xu, Xinzhong Zhu, Jiaheng Zhang
                                    <br>
                                    <em>arXiv</em>, 2026
                                    <br>
                                    <a href="https://arxiv.org/abs/2602.03328">Paper</a>
                                    /
                                    <a href="https://github.com/zzh-thu-22/GuardReasoner-Omni">Code</a>
                                    /
                                    <a href="https://huggingface.co/zhu-thu-22/GuardReasoner-Omni-2B">Model</a>
                                    <p></p>
                                      <p style="text-align:justify">


                                        We introduce a new reasoning-based multimodal guardrail model termed GuardReasoner-Omni that moderates text, image, and video content by training on a comprehensive multimodal corpus and outperforming prior baselines across guardrail benchmarks.

                                      </p>
                                  </td>
                                </tr>
                      <!--------------------------------------------------------------------------------------------------------------------------->
              

                                  

                      <!--------------------------------------------------------------------------------------------------------------------------->
                      <tr class="paper-row" data-category="foundation-models">
                        <!-- 		    bgcolor="#ffffd0" -->
                        <!--              -->
                                    <td style="padding:20px;width:25%;vertical-align:middle">
                                      <div class="one">
                                        <img src='images/kimi_k25.png' width="160">
                                      </div>
                                    </td>
                                    <td style="padding:20px;width:75%;vertical-align:middle">
                                      <a href="https://arxiv.org/abs/2602.02276">
                                        <papertitle>Kimi K2.5: Visual Agentic Intelligence </papertitle>
                                      </a>
                                      <br>
                                        <strong>Kimi Team</strong>
                                      <br>
                                      <em>Tech Report</em>, 2026
                                      <br>
                                      <a href="https://arxiv.org/abs/2602.02276">Paper</a>
                                      /
                                      <a href="https://huggingface.co/moonshotai/Kimi-K2.5">Model</a>
                                      <p></p>
                                        <p style="text-align:justify">


                                          Kimi K2.5 presents an open, multi-modal, agentic LLM that achieves strong general intelligence in agentic search, coding, and multi-modal tasks. My contribution is leading to improve extremely long-horizon coding ability, e.g., PaperBench, by data scaling, SFT, and RL.

                                       </p>
                                    </td>
                                  </tr>
                        <!--------------------------------------------------------------------------------------------------------------------------->
                
          
                        

                              <!--------------------------------------------------------------------------------------------------------------------------->
        <tr class="paper-row" data-category="foundation-models">
          <!-- 		    bgcolor="#ffffd0" -->
          <!--              -->
                      <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                          <img src='images/tb.png' width="160">
                        </div>
                      </td>
                      <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="https://arxiv.org/abs/2601.11868">
                          <papertitle style="font-size: 0.98em;">Terminal-Bench: Benchmarking Agents on Hard, Realistic Tasks in Command Line Interfaces</papertitle>
                        </a>
                        <br>
                          <strong>Terminal-Bench Team</strong>
                        <br>
                        <em>ICLR</em>, 2026
                        <br>
                        <a href="https://arxiv.org/abs/2601.11868">Paper</a>
                        /
                        <a href="https://www.tbench.ai/">Homepage</a>
                        <p></p>
                          <p style="text-align:justify">
                            Terminal-Bench introduces a realistic command-line benchmark showing that current AI agents still struggle with complex, long-horizon CLI workflows.
                            My contributions focus on proposing and implementing the tasks in Terminal-Bench.
                         </p>
                      </td>
                    </tr>
          <!--------------------------------------------------------------------------------------------------------------------------->
  
          
<!--------------------------------------------------------------------------------------------------------------------------->

<tr class="paper-row" data-category="graph-clustering">
  <!--              -->
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <img src='images/ADGC_survey.png' width="160">
                </div>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/pdf/2211.12875">
                  <papertitle>A Survey of Deep Graph Clustering: Taxonomy, Challenge, and Application</papertitle>
                </a>
                <br>
                <strong>Yue Liu</strong>,
                <a href="https://junxia97.github.io/">J. Xia</a>,
                <a href="https://scholar.google.com/citations?user=p9Se8kYAAAAJ&hl=zh-CN&oi=ao/">S. Zhou</a>,
                <a href="https://wangsiwei2010.github.io/">S. Wang</a>,
                <a href="https://scholar.google.com/citations?user=3S9i5TkAAAAJ&hl=zh-CN&oi=ao">X. Guo</a>,
                <a href="https://xihongyang1999.github.io/">X. Yang</a>,
                <a href="https://liangke23.github.io/">K. Liang</a>,
                <a href="https://wxtu.github.io/">W. Tu</a>,
                <a href="https://scholar.google.com/citations?user=Y-nyLGIAAAAJ&hl=zh-CN&oi=ao">Stan Z. Li</a>,
                <a href="https://xinwangliu.github.io/">X. Liu</a>
                <br>
                <em>IEEE T-KDE</em>, 2026
                <br>
                <a href="https://arxiv.org/pdf/2211.12875">Paper</a>
                /
                <a href="https://github.com/yueliu1999/Awesome-Deep-Graph-Clustering">Project</a>
                <p></p>
                <p style="text-align:justify">
                  Deep graph clustering, which aims to group the nodes in graph into disjoint clusters, has become a new hot research spot. This paper summarizes the taxonomy, challenge, and application of deep graph clustering. We hope this work will serve as a quick guide and help researchers to overcome the challenges in this field.
                </p>
              </td>
            </tr>
  


                      <!--------------------------------------------------------------------------------------------------------------------------->
        <tr class="paper-row" data-category="foundation-models">
          <!-- 		    bgcolor="#ffffd0" -->
          <!--              -->
                      <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                          <img src='images/kimi_k2.png' width="160">
                        </div>
                      </td>
                      <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="https://arxiv.org/abs/2507.20534">
                          <papertitle>Kimi K2: Open Agentic Intelligence</papertitle>
                        </a>
                        <br>
                          <strong>Kimi Team</strong>
                        <br>
                        <em>Tech Report</em>, 2025
                        <br>
                        <a href="https://arxiv.org/abs/2507.20534">Paper</a>
                        /
                        <a href="https://huggingface.co/moonshotai/Kimi-K2-Instruct">Model</a>
                        <p></p>
                          <p style="text-align:justify">
                            Kimi K2 presents an open, agentic LLM that achieves strong general intelligence in coding, tool-use, etc. My contributions focus on improving agentic coding ability, including leading evaluation for AI scientist (PaperBench) and engaging in Docker scaling and scaffold scaling.
                         </p>
                      </td>
                    </tr>
          <!--------------------------------------------------------------------------------------------------------------------------->
  
          

                                <!--------------------------------------------------------------------------------------------------------------------------->
        <tr class="paper-row" data-category="llm-safety">
          <!-- 		    bgcolor="#ffffd0" -->
          <!--              -->
                      <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                          <img src='images/GuardReasoner_VL.png' width="160">
                        </div>
                      </td>
                      <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="https://arxiv.org/abs/2505.11049">
                          <papertitle>GuardReasoner-VL: Safeguarding VLMs via Reinforced Reasoning</papertitle>
                        </a>
                        <br>

                        </a></h2>
<!-- [Yue Liu](https://yueliu1999.github.io/), [Shengfang Zhai](https://zhaisf.github.io/), [Mingzhe Du](https://mingzhe.space/)
<br>
[Yulin Chen](https://sg.linkedin.com/in/yulin-chen-00a99828b), [Tri Cao](), [Hongcheng Gao](https://hongcheng-gao.github.io/), [Cheng Wang](https://scholar.google.com/citations?user=z7idU9gAAAAJ&hl=en)
<br>
[Xinfeng Li](https://openreview.net/profile?id=~Xinfeng_Li1), [Kun Wang](https://scholar.google.com/citations?user=UnyqjWQAAAAJ&hl=en), [Junfeng Fang](https://scholar.google.com/citations?user=beNNywsAAAAJ&hl=zh-CN), [Jiaheng Zhang](https://zjhzjh123.github.io/), [Bryan Hooi](https://bhooi.github.io/)
<br>
<sup>1</sup>[National University of Singapore](https://nus.edu.sg/), <sup>2</sup>[Nanyang Technological University](https://www.ntu.edu.sg/)
</div> -->



                          <strong>Yue Liu</strong>,
                          <a href="https://zhaisf.github.io/">Shengfang Zhai</a>,
                          <a href="https://mingzhe.space/">Mingzhe Du</a>,
                          <a href="https://github.com/LukeChen-go">Yulin Chen</a>,
                          <a href="https://caothientri2001vn.github.io/">Tri Cao</a>,
                          <a href="https://hongcheng-gao.github.io/">Hongcheng Gao</a>,
                          <a href="https://scholar.google.com/citations?user=z7idU9gAAAAJ&hl=en">Cheng Wang</a>,
                          <a href="https://openreview.net/profile?id=~Xinfeng_Li1">Xinfeng Li</a>,
                          <a href="https://scholar.google.com/citations?user=UnyqjWQAAAAJ&hl=en">Kun Wang</a>,
                          <a href="https://scholar.google.com/citations?user=beNNywsAAAAJ&hl=zh-CN">Junfeng Fang</a>,
                          <a href="https://zjhzjh123.github.io/">Jiaheng Zhang</a>,
                          <a href="https://bhooi.github.io/">Bryan Hooi</a>
                        <br>
                        <em>NeurIPS</em>, 2025
                        <br>
                        <a href="https://arxiv.org/abs/2505.11049">Paper</a>
                        /
                        <a href="https://github.com/yueliu1999/GuardReasoner-VL">Code</a>
			/
                        <a href="https://huggingface.co/yueliu1999/GuardReasoner-VL-7B">Model</a>
                        /
                        <a href="https://huggingface.co/datasets/yueliu1999/GuardReasoner-VLTrain">Data</a>
                        <p></p>
                        <p style="text-align:justify">

                          We propose a new VLM safeguard termed GuardReasoner-VL by incentivize the guard model to deliberatively reason before making moderation decisions via online RL. Experiments on 14 multi-modal benchmarks demonstrate the superiority. 
<!-- guiding it to learn to reason. It improves the reasoning ability, explainability, and generalizability via Reasoning SFT and Hard-Sample DPO -->
                        </p>
                      </td>
                    </tr>
          <!--------------------------------------------------------------------------------------------------------------------------->
  


                                <!--------------------------------------------------------------------------------------------------------------------------->
        <tr class="paper-row" data-category="llm-safety">
          <!-- 		    bgcolor="#ffffd0" -->
          <!--              -->
                      <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                          <img src='images/lrm_safety.png' width="160">
                        </div>
                      </td>
                      <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="https://arxiv.org/pdf/2504.17704">
                          <papertitle>Safety in Large Reasoning Models: A Survey</papertitle>
                        </a>
                        <br>
                        Cheng Wang*, <strong>Yue Liu*</strong>, Baolong Bi, Duzhen Zhang, Zhong-Zhi Li, Yingwei Ma, Yufei He, Shengju Yu, Xinfeng Li, Junfeng Fang, Jiaheng Zhang, Bryan Hooi
                        <br>
                        <em>EMNLP Findings</em>, 2025
                        <br>
                        <a href="https://arxiv.org/pdf/2504.17704">Paper</a>
                        /
                        <a href="https://github.com/WangCheng0116/Awesome-LRMs-Safety">Code</a>
                        <p></p>
                        <p style="text-align:justify">

                          This survey provides a comprehensive taxonomy of emerging safety risks, attacks, and defenses specific to large reasoning models to guide future research on their secure and reliable deployment.
<!-- guiding it to learn to reason. It improves the reasoning ability, explainability, and generalizability via Reasoning SFT and Hard-Sample DPO -->
                        </p>
                      </td>
                    </tr>
          <!--------------------------------------------------------------------------------------------------------------------------->
  

                      <!--------------------------------------------------------------------------------------------------------------------------->
        <tr class="paper-row" data-category="foundation-models">
          <!-- 		    bgcolor="#ffffd0" -->
          <!--              -->
                      <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                          <img src='images/FlowReasoner.png' width="160">
                        </div>
                      </td>
                      <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="https://arxiv.org/abs/2504.15257">
                          <papertitle>FlowReasoner: Reinforcing Query-Level Meta-Agents</papertitle>
                        </a>
                        <br>
                        <a href="https://hongcheng-gao.github.io/">Hongcheng Gao*</a>,
                          <strong>Yue Liu*</strong>,
                          <a href="https://scholar.google.com/citations?user=_3HjpOMAAAAJ&hl=en">Y. He</a>,
                          <a href="https://longxudou.github.io/">L. Dou</a>,
                          <a href="https://duchao0726.github.io/">C. Du</a>,
                          <a href="https://scholar.google.com/citations?user=J3dR0sUAAAAJ&hl=en">Z. Deng</a>,
                          <a href="https://bhooi.github.io/">Bryan Hooi</a>,
                          <a href="https://scholar.google.com.sg/citations?user=BGONmkIAAAAJ&hl=en">Min Lin</a>,
                          <a href="https://p2333.github.io/">Tianyu Pang</a>
                        <br>
                        <em>ICML MAS Workshop</em>, 2025
                        <br>
                        <a href="https://arxiv.org/abs/2504.15257">Paper</a>
                        /
                        <a href="https://github.com/sail-sg/FlowReasoner">Code</a>
                        <p></p>
                        <p style="text-align:justify">
                          We propose a reasoning-based meta-agent termed FlowReasoner to automate the design of query-level multi-agent systems, i.e., one systems per query, using distillation and reinforcement learning from external execution feedback.

                        </p>
                      </td>
                    </tr>
          <!--------------------------------------------------------------------------------------------------------------------------->
  
          
                            <!--------------------------------------------------------------------------------------------------------------------------->
        <tr class="paper-row" data-category="foundation-models">
          <!-- 		    bgcolor="#ffffd0" -->
          <!--              -->
                      <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                          <img src='images/lrm_survey.png' width="160">
                        </div>
                      </td>
                      <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="https://arxiv.org/pdf/2503.23077">
                          <papertitle>Efficient Inference for Large Reasoning Models: A Survey</papertitle>
                        </a>
                        <br>
                          <strong>Yue Liu*</strong>,
                          <a href="https://jiayingwu19.github.io/">J. Wu*</a>,
                          <a href="https://scholar.google.com/citations?user=_3HjpOMAAAAJ&hl=en">Y. He*</a>,
                          <a href="https://hongcheng-gao.github.io/">H. Gao</a>,
                          <a href="">H. Chen</a>,
                          <a href="https://byronbbl.github.io/">B. Bi</a>,
                          <a href="https://zjhzjh123.github.io/">Jiaheng Zhang</a>,
                          <a href="https://scholar.google.com/citations?user=5JGMGCsAAAAJ&hl=zh-CN">Zhiqi Huang</a>,
                          <a href="https://bhooi.github.io/">Bryan Hooi</a>

                        <br>
                        <em>arXiv</em>, 2025
                        <br>
                        <a href="https://arxiv.org/pdf/2503.23077">Paper</a>
                        /
                        <a href="https://github.com/yueliu1999/Awesome-Efficient-Inference-for-LRMs">Project</a>
                        <p></p>
                        <p style="text-align:justify">
                          We conduct a comprehensive survey on efficient inference for large reasoning models (LRMs). We categorize the existing methods into two main categories explicit compact CoT and implicit latent CoT. We summarize the challenges and highlight further improvement. 

                        </p>
                      </td>
                    </tr>
          <!--------------------------------------------------------------------------------------------------------------------------->
  


          
            <!--------------------------------------------------------------------------------------------------------------------------->
        <tr class="paper-row" data-category="llm-safety">
          <!-- 		    bgcolor="#ffffd0" -->
          <!--              -->
                      <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                          <img src='images/GuardReasoner.png' width="160">
                        </div>
                      </td>
                      <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="https://arxiv.org/abs/2501.18492">
                          <papertitle>GuardReasoner: Towards Reasoning-based LLM Safeguards</papertitle>
                        </a>
                        <br>
                          <strong>Yue Liu</strong>,
                          <a href="https://hongcheng-gao.github.io/">H. Gao</a>,
                          <a href="https://zhaisf.github.io/">S. Zhai</a>,
                          <a href="https://junxia97.github.io/">J. Xia</a>,
                          <a href="https://andrewwty.github.io/">T. Wu</a>,
                          <a href="">Z. Xue</a>,
                          <a href="https://github.com/LukeChen-go">Y. Chen</a>,
                          <a href="https://ml.comp.nus.edu.sg/kawaguchi">K. Kawaguchi</a>,
                          <a href="https://zjhzjh123.github.io/">J. Zhang</a>,
                          <a href="https://bhooi.github.io/">Bryan Hooi</a>

                        <br>
                        <em>ICLR FM-Wild Workshop</em>, 2025
                        <br>
                        <a href="https://arxiv.org/abs/2501.18492">Paper</a>
                        /
                        <a href="https://github.com/yueliu1999/GuardReasoner">Code</a>
                        /
                        <a href="https://huggingface.co/yueliu1999/GuardReasoner-8B">Model</a>
                        /
                        <a href="https://huggingface.co/datasets/yueliu1999/GuardReasonerTrain">Data</a>
                        <p></p>
                        <p style="text-align:justify">
                          We propose a new LLM safeguard termed GuardReasoner by guiding it to learn to reason. It improves the reasoning ability, explainability, and generalizability via Reasoning SFT and Hard-Sample DPO. Experiments on 13 benchmarks of 3 guardrail tasks demonstrate the superiority. The data, code, and models (1B, 3B, 8B) are released. 

                        </p>
                      </td>
                    </tr>
          <!--------------------------------------------------------------------------------------------------------------------------->
  


            <!--------------------------------------------------------------------------------------------------------------------------->
        <tr class="paper-row" data-category="llm-safety">
          <!-- 		    bgcolor="#ffffd0" -->
          <!--              -->
                      <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                          <img src='images/FlipAttack.png' width="160">
                        </div>
                      </td>
                      <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="https://arxiv.org/pdf/2410.02832">
                          <papertitle>FlipAttack: Jailbreak LLMs via Flipping</papertitle>
                        </a>
                        <br>
                          <strong>Yue Liu</strong>,
                          <a href="https://xiaoxinhe.github.io/">Xiaoxin He</a>,
                          <a href="https://miaoxiong2320.github.io/">Miao Xiong</a>,
                          <a href="https://jinlanfu.github.io/">Jinlan Fu</a>,
                          <a href="https://231sm.github.io/">Shumin Deng</a>,
                          <a href="https://bhooi.github.io/">Bryan Hooi</a>

                        <br>
                        <em>ICML</em>, 2025
                        <br>
                        <a href="https://arxiv.org/pdf/2410.02832">Paper</a>
                        /
                        <a href="https://github.com/yueliu1999/FlipAttack">Code</a>
                        <p></p>
                        <p style="text-align:justify">
                          We propose a simple yet effective jailbreak attack termed FlipAttack against black-box LLMs within only 1 query. By analyzing LLMs' understanding mechanism, we design 4 flipping modes to disguise the attack. Then, we guide LLMs understand and execute the harmful behaivors. Experiments on 8 LLMs and 5 guards demonstrate the superiority.

                        </p>
                      </td>
                    </tr>
          <!--------------------------------------------------------------------------------------------------------------------------->
  

        <!--------------------------------------------------------------------------------------------------------------------------->
        <tr class="paper-row" data-category="recommendation">
          <!-- 		    bgcolor="#ffffd0" -->
          <!--              -->
                      <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                          <img src='images/ITR.png' width="160">
                        </div>
                      </td>
                      <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="https://arxiv.org/pdf/2410.23757.pdf">
                          <papertitle>Identify Then Recommend: Towards Unsupervised Group Recommendation</papertitle>
                        </a>
                        <br>
                          <strong>Yue Liu</strong>,
                          S. Zhu,
                          T. Yang,
                          J. Ma,
                          Wenliang Zhong
                        <br>
                        <em>NeurIPS</em>, 2024
                        <br>
                        <a href="https://arxiv.org/pdf/2410.23757.pdf">Paper</a>
                        /
                        <a href="https://github.com/yueliu1999/ITR">Code</a>
                        <p></p>
                        <p style="text-align:justify">
                            We propose an unsupervised group recommendation method named ITR first to identify user groups and then conduct self-supervised group recommendation via two pre-text tasks. Results on both open data and industrial data show the effectiveness. 
          
                        </p>
                      </td>
                    </tr>
          <!--------------------------------------------------------------------------------------------------------------------------->
  
                                        
		                        <!--------------------------------------------------------------------------------------------------------------------------->
            <tr class="paper-row" data-category="recommendation">
<!-- 		    bgcolor="#ffffd0" -->
<!--              -->
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/ELCRec.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2401.05975.pdf">
                <papertitle>End-to-end Learnable Clustering for Intent Learning in Recommendation</papertitle>
              </a>
              <br>
                <strong>Yue Liu*</strong>,
                Shihao Zhu*,
                <a href="https://junxia97.github.io/">J. Xia</a>,
                Y. Ma,
                J. Ma,
                W. Zhong,
                G. Zhang,
                K. Zhang,
                <a href="https://xinwangliu.github.io/">Xinwang Liu</a>
              <br>
              <em>NeurIPS</em>, 2024
              <br>
              <a href="https://arxiv.org/pdf/2401.05975.pdf">Paper</a>
              /
              <a href="https://github.com/yueliu1999/ELCRec">Code</a>
              <p></p>
              <p style="text-align:justify">
<!--                  We propose an intent learning method named ELCRec via end-to-end learnable clustering and cluster-assisted contrastive learning for recommendation. Both the results on open benchmarks and industrial engines demonstrate superiority and effectiveness.-->
                  We propose an intent learning method termed ELCRec, which leverages end-to-end learnable clustering and cluster-assisted contrastive learning to improve recommendation. Both the results on open benchmarks and industrial engines demonstrate the superiority.
<!--                Our method exhibits superior performance and effectiveness, as demonstrated by experiments on open benchmarks and an industrial engine.-->

              </p>
            </td>
          </tr>
<!--------------------------------------------------------------------------------------------------------------------------->
		
				                <!--------------------------------------------------------------------------------------------------------------------------->
            <tr class="paper-row" data-category="graph-clustering">
<!--              -->
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/IDCRN.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2202.12533">
                <papertitle>Improved Dual Correlation Reduction Network with Affinity Recovery</papertitle>
              </a>
              <br>
                <strong>Yue Liu</strong>*,
		Sihang Zhou*,
		X. Yang,
                <a href="https://xinwangliu.github.io/">Xinwang Liu</a>,
		W. Tu,
		L. Li,
		Xin Xu,
		Funchun Sun,

              <br>
              <em>IEEE T-NNLS</em>, 2024
              <br>
              <a href="https://arxiv.org/pdf/2202.12533">Paper</a>
              /
              <a href="https://github.com/yueliu1999/IDCRN">Code</a>
              <p></p>
              <p style="text-align:justify">
                  We explore deep-in reasons of representation collapse in deep graph clustering and improve the dual correlation reduction network with the affinity recovery strategy.
	      </p>
            </td>
          </tr>
<!--------------------------------------------------------------------------------------------------------------------------->
		

                <!--------------------------------------------------------------------------------------------------------------------------->
            <tr class="paper-row" data-category="graph-clustering">
<!--              -->
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/TGC.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2305.10738">
                <papertitle>Deep Temporal Graph Clustering</papertitle>
              </a>
              <br>
                <a href="https://mgithubl.github.io/">Meng Liu</a>,
                <strong>Yue Liu</strong>,
                K. Liang,
                S. Wang,
                S. Zhou,
                <a href="https://xinwangliu.github.io/">Xinwang Liu</a>

		    
              <br>
              <em>ICLR</em>, 2024.
              <br>
              <a href="https://arxiv.org/pdf/2305.10738">Paper</a>
              /
              <a href="https://github.com/MGitHubL/Deep-Temporal-Graph-Clustering">Code</a>
              <p></p>
              <p style="text-align:justify">
                  We aim to extend deep graph clustering to temporal graphs, which are more practical in real-world scenarios. We propose a general framework TGC by clustering distribution assignment and adjacency reconstruction.

              </p>
            </td>
          </tr>
          
<!--------------------------------------------------------------------------------------------------------------------------->

        <!--------------------------------------------------------------------------------------------------------------------------->
            <tr class="paper-row" data-category="foundation-models">
<!--              -->
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/code_LLMs.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2309.16298">
                <papertitle>At Which Training Stage Does Code Data Help LLM Reasoning?</papertitle>
              </a>
              <br>
                <a href="https://yingweima2022.github.io/">Yingwei Ma</a>*,
                <strong>Yue Liu</strong>*,
                Y. Yu,
                Y. Jiang,
                C. Wang,
                S. Li
              <br>
              <em>ICLR (<font color="red">Spotlight</font>)</em>, 2024
              <br>
              <a href="https://arxiv.org/abs/2309.16298">Paper</a>
              /
              <a href="https://github.com/yingweima2022/CodeLLM">Code</a>
              <p></p>
              <p style="text-align:justify">
                  We explore at which training stage code data can help LLMs reason. The extensive experiments and insights deepen our understanding of LLMs' reasoning capability and the corresponding applications, e.g., scientific question answering, legal support, etc.



<!--                  We propose a plug-and-play knowledge graph contrastive learning method named KGE-SymCL by mining the symmetrical structure information in knowledge graphs.-->
              </p>
            </td>
          </tr>

                        <!--------------------------------------------------------------------------------------------------------------------------->
            <tr class="paper-row" data-category="graph-clustering">
<!--              -->
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/RGC.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2308.06827">
                <papertitle>Reinforcement Graph Clustering with Unknown Cluster Number</papertitle>
              </a>
              <br>
                <strong>Yue Liu</strong>,
                <a href="https://liangke23.github.io/">Ke Liang</a>,
                <a href="https://junxia97.github.io/">Jun Xia</a>,
                <a href="https://xihongyang1999.github.io/">X. Yang</a>,
                <a href="https://scholar.google.com/citations?user=p9Se8kYAAAAJ&hl=zh-CN&oi=ao/">S. Zhou</a>,
                <a href="https://mgithubl.github.io/">Meng Liu</a>,
                <a href="https://xinwangliu.github.io/">Xinwang Liu</a>,
                <a href="https://scholar.google.com/citations?user=Y-nyLGIAAAAJ&hl=zh-CN&oi=ao">Stan Z. Li</a>
              <br>
              <em>ACM MM</em>, 2023
              <br>
              <a href="https://arxiv.org/pdf/2308.06827">Paper</a>
              /
              <a href="https://github.com/yueliu1999/RGC">Code</a>
              <p></p>
              <p style="text-align:justify">
		  We show that the promising performance of deep graph clustering methods relies on the pre-defined cluster number and propose RGC to determine the cluster number via reinforcement learning. 
              </p>
            </td>
          </tr>
<!--------------------------------------------------------------------------------------------------------------------------->

<!--------------------------------------------------------------------------------------------------------------------------->
            <tr class="paper-row" data-category="knowledge-graph">
<!--              -->
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/liu_KGE-SymCL.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2211.10738.pdf">
                <papertitle>Knowledge Graph Contrastive Learning based on Relation-Symmetrical Structure</papertitle>
              </a>
              <br>
                <a href="https://liangke23.github.io/">Ke Liang</a>*,
                <strong>Yue Liu</strong>*,
                <a href="https://scholar.google.com/citations?user=p9Se8kYAAAAJ&hl=zh-CN&oi=ao/">S. Zhou</a>,
                <a href="https://wxtu.github.io/">W. Tu</a>,
                Y. Wen,
                <a href="https://xihongyang1999.github.io/">X. Yang</a>,
                X. Dong,
                <a href="https://xinwangliu.github.io/">Xinwang Liu</a>
              <br>
              <em>IEEE T-KDE (<font color="red">ESI Highly Cited Paper</font>)</em>, 2023
              <br>
              <a href="https://arxiv.org/pdf/2211.10738.pdf">Paper</a>
              /
              <a href="">Code</a>
              <p></p>
              <p style="text-align:justify">
                  We propose a plug-and-play knowledge graph contrastive learning method named KGE-SymCL by mining the symmetrical structure information in knowledge graphs.
              </p>
            </td>
          </tr>
<!--------------------------------------------------------------------------------------------------------------------------->

            <tr class="paper-row" data-category="graph-clustering">
<!-- 		     bgcolor="#ffffd0" -->
<!--              -->
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/liu_Dink-Net.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2305.18405.pdf">
                <papertitle>Dink-Net: Neural Clustering on Large Graphs</papertitle>
              </a>
              <br>
                <strong>Yue Liu</strong>,
                <a href="https://liangke23.github.io/">K. Liang</a>,
                <a href="https://junxia97.github.io/">Jun Xia</a>,
                <a href="https://scholar.google.com/citations?user=p9Se8kYAAAAJ&hl=zh-CN&oi=ao/">S. Zhou</a>,
                <a href="https://xihongyang1999.github.io/">X. Yang</a>,
                <a href="https://xinwangliu.github.io/">Xinwang Liu</a>,
                <a href="https://scholar.google.com/citations?user=Y-nyLGIAAAAJ&hl=zh-CN&oi=ao">Stan Z. Li</a>
              <br>
              <em>ICML</em>, 2023
              <br>
              <a href="https://arxiv.org/pdf/2305.18405.pdf">Paper</a>
                /
              <a href="https://github.com/yueliu1999/Dink-Net">Code</a>

              <p></p>
              <p style="text-align:justify">
                  We analyze the drawbacks of existing deep graph clustering methods and scale deep graph clustering to large-scale graphs. The proposed shrink and dilation loss functions optimize clustering distribution adversarially, allowing batch training without performance dropping.
              </p>
            </td>
          </tr>
<!--------------------------------------------------------------------------------------------------------------------------->

            <tr class="paper-row" data-category="graph-clustering">
<!--              -->
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/liu_SCGC.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2205.07865">
                <papertitle>Simple Contrastive Graph Clustering</papertitle>
              </a>
              <br>
                <strong>Yue Liu</strong>,
                <a href="https://xihongyang1999.github.io/">X. Yang</a>,
                <a href="https://scholar.google.com/citations?user=p9Se8kYAAAAJ&hl=zh-CN&oi=ao/">S. Zhou</a>,
                <a href="https://xinwangliu.github.io/">Xinwang Liu</a>,
                <a href="https://wangsiwei2010.github.io/">S. Wang</a>,
                <a href="https://liangke23.github.io/">K. Liang</a>,
                <a href="https://wxtu.github.io/">W. Tu</a>,
                <a href="https://liliangnudt.github.io/">L. Li</a>,

              <br>
              <em>IEEE T-NNLS</em>, 2023
              <br>
              <a href="https://arxiv.org/abs/2205.07865">Paper</a>
              /
              <a href="https://github.com/yueliu1999/SCGC">Code</a>
              <p></p>
              <p style="text-align:justify">
                  We propose to replace the complicated and consuming graph data augmentations by designing parameter un-shared Siamese encoders and perturbing node embeddings.

              </p>
            </td>
          </tr>

<!--------------------------------------------------------------------------------------------------------------------------->

<!--------------------------------------------------------------------------------------------------------------------------->
            <tr class="paper-row" data-category="graph-clustering">
<!-- 		    bgcolor="#ffffd0" -->
<!--              -->
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/liu_HSAN.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2212.08665">
                <papertitle>Hard Sample Aware Network for Contrastive Deep Graph Clustering</papertitle>
              </a>
              <br>
              <strong>Yue Liu</strong>,
              <a href="https://xihongyang1999.github.io/">X. Yang</a>,
              <a href="https://scholar.google.com/citations?user=p9Se8kYAAAAJ&hl=zh-CN&oi=ao/">S. Zhou</a>,
              <a href="https://xinwangliu.github.io/">X. Liu</a>,
              Z. Wang,
              <a href="https://liangke23.github.io/">K. Liang</a>,
              <a href="https://wxtu.github.io/">W. Tu</a>,
              L. Li,
              J. Duan,
              C. Chen
              <br>
              <em>AAAI (<font color="red">Oral & Most Influential AAAI Paper</font>)</em> (13/539) [<a href="https://www.paperdigest.org/2023/09/most-influential-aaai-papers-2023-09/">Link</a>], 2023 
              <br>
              <a href="https://arxiv.org/abs/2212.08665">Paper</a>
              /
              <a href="https://github.com/yueliu1999/HSAN">Code</a>
              <p></p>
              <p style="text-align:justify">
                We propose a Hard Sample Aware Network (HSAN) to mine both the hard positive samples and hard negative samples with a comprehensive similarity measure criterion and a general dynamic sample weighing strategy.
              </p>
            </td>
          </tr>




          <tr class="paper-row" data-category="graph-clustering">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/DCRN.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2112.14772">
                <papertitle>Deep Graph Clustering via Dual Correlation Reduction</papertitle>
              </a>
              <br>
              <strong>Yue Liu</strong>*,
<!--              Yue Liu, Wenxuan Tu, Sihang Zhou, Xinwang Liu, Linxuan Song, Xihong Yang, En Zhu-->
              <a href="https://wxtu.github.io/">Wenxuan Tu</a>*,
              <a href="https://scholar.google.com/citations?user=p9Se8kYAAAAJ&hl=zh-CN&oi=ao">S. Zhou</a>,
              <a href="https://xinwangliu.github.io/">X. Liu</a>,
              L. Song,
              <a href="https://xihongyang1999.github.io/">X. Yang</a>,
              E. Zhu
              <br>
              <em>AAAI</em>, 2022
              <br>
              <a href="https://arxiv.org/abs/2112.14772">Paper</a>
              /
              <a href="https://github.com/yueliu1999/DCRN">Code</a>
              <p></p>
              <p style="text-align:justify">
              We propose a self-supervised deep graph clustering method termed Dual Correlation Reduction Network (DCRN) to address the representation collapse issue by reducing information correlation in both sample and feature levels.
              </p>
            </td>
          </tr>
<!--------------------------------------------------------------------------------------------------------------------------->

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <tr>
  <td style="padding:20px;width:100%;vertical-align:middle">
    <!-- <heading>Research</heading> -->
    
    <p>
      <em>"If we knew what it was we were doing, it would not be called research, would it?"</em> &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp  &nbsp &nbsp &nbsp <em>--Albert Einstein</em>


<!-- 		      The representative papers are <span class="highlight">highlighted</span>. -->
    </p>
  </td>
</tr>
</tbody></table>

  

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Experience</heading>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
            <ul>
            <li>Associate Member @ <a href="https://sail.sea.com/">Sea AI Lab</a>, advised by Dr. <a href="https://p2333.github.io/">Tianyu Pang</a></li></li>
            <li>Research Assistant @ <a href="https://en.westlake.edu.cn/">Westlake University</a>, working with <a href="https://junxia97.github.io/">Jun Xia</a>, advised by Prof. <a href="https://scholar.google.com/citations?user=Y-nyLGIAAAAJ&hl=zh-CN&oi=ao">Stan Z. Li</a></li></li>
            <li>Research Assistant @ <a href="http://english.ia.cas.cn/">Institute of Automation</a>, working with <a href="https://yuheng2000.github.io/">Yuheng Ji</a>, advised by Prof. <a href="https://scholar.google.com/citations?user=fAwC8RwAAAAJ&hl=zh-CN">Xiaolong Zheng</a></li></li>
            <li>Senior Recommendation Algorithm Engineer @ <a href="https://www.alipay.com/">Alipay Co., Ltd.</a></li></li>
<!--             <li>Master of Engineering @ <a href="https://english.nudt.edu.cn/">National University of Defence Technology</a>, advised by Prof. <a href="https://xinwangliu.github.io/">Xinwang Liu</a></li> -->
	    <li>Recommendation Algorithm Engineer Intern @ <a href="https://www.antgroup.com/en">Ant Group Co., Ltd.</a></li></li>
            <li>Financial Risk Control Algorithm Engineer Intern @ <a href="https://www.meituan.com/">Meituan Co., Ltd.</a></li></li>
            <li>3D Vision Algorithm Engineer Intern @ <a href="https://speedbot.ca/">SpeedBot Robotics Co., Ltd.</a>, advised by Prof. <a href="https://kevinkaixu.net/">Kai Xu</a></li>
<!--             <li>3D Vision Algorithm Engineer Intern @ <a href="https://speedbot.ca/">SpeedBot Robotics Co., Ltd.</a> -->
<!-- 		    , supervised by Prof. <a href="https://kevinkaixu.net/">Kai Xu</a></li> -->
            <li>Bachelor of Engineering @ <a href="http://english.neu.edu.cn/">Northeastern University</a></li>
            </ul>
        </table>


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Service</heading>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
            <ul>
	    <li>Reviewer for ICML, NeurIPS, ICLR</li>
            <li>Reviewer for CVPR, ICCV, ECCV</li>
            <li>Reviewer for ACL, EMNLP, COLING, COLM</li>
            <li>Reviewer for AAAI, IJCAI, ACM MM, AISTATS</li>
            <li>Reviewer for KDD, WWW, CIKM, WSDM, LoG</li>
	        <li>Reviewer for  IEEE T-KDE, IEEE T-NNLS, IEEE T-MM, IEEE T-CYB</li>
<!--             <li>Reviewer for ICML'24/25, ICLR'24/25, NeurIPS'23/24</li> -->
<!--             <li>Reviewer for CVPR'24/25, ICCV'25</li> -->
<!--             <li>Reviewer for ACL'25, EMNLP'23, COLING'25</li> -->
<!--             <li>Reviewer for AAAI'23/24/25, IJCAI'25, ACM MM'23/24, AISTATS'25</li> -->
<!--             <li>Reviewer for KDD'24/25, WWW'24, CIKM'23/24, WSDM'23/24/25, LoG'24</li> -->
<!-- 	    <li>Reviewer for  IEEE T-KDE, IEEE T-NNLS, IEEE T-MM</li> -->
		    
<!--             <li>Reviewer for PRCV'22/23, IEEE/CAA JAS, IEEE T-NNLS, Pattern Recognition</li> -->
<!--             <li>Reviewer for PRCV 2022</li> -->
<!--             <li>Reviewer for NeurIPS 2023</li> -->
<!--             <li>Reviewer for ACM MM 2023</li> -->
            </ul>
        </table>


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Award</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
            <ul>
            <li>Research Award, NUS. [<a href="images/ids.jpg">PDF</a>]</li>
            <li>Dean's Graduate Research Excellence Award, NUS. [<a href="images/dean.png">PDF</a>]</li>
            <li>Intech Award (PhD Track), Ant Group. [<a href="images/ant_group_intech.jpg">PDF</a>]</li>
            <li>President's Graduate Fellowship, National University of Singapore. [<a href="https://nusgs.nus.edu.sg/scholarships/presidents-graduate-fellowship/">Link</a>]</li>
            <li>China National Scholarship. [<a href="images/National Scholarship 2023.pdf">PDF</a>]</li>
            <li>China National Scholarship. [<a href="images/National Scholarship 2022.pdf">PDF</a>]</li>
            <li>China National Scholarship. [<a href="images/National Scholarship 2020.pdf">PDF</a>]</li>
            </ul>
        </table>


        <p align="center">Design and source code from <a href="https://jonbarron.info/">Jon Barron</a>'s website</p>
        <script>
          let show = false;
          document.querySelector('#projects-show').onclick = function() {
            if (!show) {
              document.querySelector('#projects-box').style.height = 'auto';
              document.querySelector('#projects-box').style.paddingBottom = '20px';
              document.querySelector('#projects-show-text').innerHTML = 'Less';
              show = true;
            } else {
              show = false;
              document.querySelector('#projects-box').style.height = '160px';
              document.querySelector('#projects-box').style.paddingBottom = '0px';
              document.querySelector('#projects-show-text').innerHTML = 'More';
            }
          }
          
          function filterPapers(category) {
            // Update button states
            const buttons = document.querySelectorAll('.category-btn');
            buttons.forEach(btn => {
              if (btn.getAttribute('data-category') === category) {
                btn.classList.add('active');
              } else {
                btn.classList.remove('active');
              }
            });
            
            // Filter papers
            const papers = document.querySelectorAll('.paper-row');
            papers.forEach(paper => {
              if (category === 'all' || paper.getAttribute('data-category') === category) {
                paper.classList.remove('hidden');
              } else {
                paper.classList.add('hidden');
              }
            });
          }
          
          // Style author links to look like plain text
          function styleAuthorLinks() {
            const papers = document.querySelectorAll('.paper-row');
            papers.forEach(paper => {
              const paperTd = paper.querySelectorAll('td')[1];
              if (paperTd) {
                const allLinks = paperTd.querySelectorAll('a');
                allLinks.forEach(link => {
                  const text = link.textContent.trim();
                  // Check if it's an author link (not Paper/Code/Model/Data/Homepage/Project or papertitle)
                  if (text !== 'Paper' && text !== 'Code' && text !== 'Model' && text !== 'Data' && text !== 'Homepage' && text !== 'Project' &&
                      !link.querySelector('papertitle') &&
                      !text.includes('arxiv.org') && !text.includes('github.com') && 
                      !text.includes('huggingface.co')) {
                    link.classList.add('author-link');
                  }
                });
              }
            });
          }
          
          // Add tags to papers at the conference/venue line
          function addPaperTags() {
            const categoryMap = {
              'llm-safety': 'Safety of Foundation Models',
              'foundation-models': 'Intelligence of Foundation Models',
              'graph-clustering': 'Graph Clustering',
              'knowledge-graph': 'Knowledge Graph Embedding',
              'recommendation': 'Recommendation Systems'
            };
            
            const papers = document.querySelectorAll('.paper-row');
            papers.forEach(paper => {
              const category = paper.getAttribute('data-category');
              if (category && categoryMap[category]) {
                const paperTd = paper.querySelectorAll('td')[1];
                if (paperTd) {
                  const existingTag = paperTd.querySelector('.paper-tag');
                  if (!existingTag) {
                    // Find the venue line - look for <em> tag (venue name)
                    const emTag = paperTd.querySelector('em');
                    
                    if (emTag) {
                      const tag = document.createElement('span');
                      tag.className = 'paper-tag';
                      tag.textContent = categoryMap[category];
                      
                      // Insert tag BEFORE the em tag so float:right puts it on the same line
                      emTag.parentNode.insertBefore(tag, emTag);
                    }
                  }
                }
              }
            });
          }
          
          // Call when page loads
          function initPapers() {
            styleAuthorLinks();
            addPaperTags();
          }
          
          if (document.readyState === 'loading') {
            document.addEventListener('DOMContentLoaded', initPapers);
          } else {
            initPapers();
          }
        </script>
</body>
<div style="display: inline-block; transform: scale(0.1); transform-origin: center;">
    <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=UiqBMJTxY6SnX78N7hPnPO3hP-MX9TXJcBTDnU7x4r4"></script>
</div>
</html>
